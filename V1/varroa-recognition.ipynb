{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-03-03T13:51:48.576204Z","iopub.status.busy":"2023-03-03T13:51:48.575829Z","iopub.status.idle":"2023-03-03T13:51:54.421541Z","shell.execute_reply":"2023-03-03T13:51:54.419974Z","shell.execute_reply.started":"2023-03-03T13:51:48.576172Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tensorflow==2.6.4\n","  Downloading tensorflow-2.6.4-cp37-cp37m-win_amd64.whl (429.2 MB)\n","     -------------------------------------- 429.2/429.2 MB 3.9 MB/s eta 0:00:00\n","Collecting numpy~=1.19.2\n","  Downloading numpy-1.19.5-cp37-cp37m-win_amd64.whl (13.2 MB)\n","     --------------------------------------- 13.2/13.2 MB 31.2 MB/s eta 0:00:00\n","Collecting six~=1.15.0\n","  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n","Collecting opt-einsum~=3.3.0\n","  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n","Requirement already satisfied: wheel~=0.35 in c:\\users\\louis\\documents\\github\\varroa-detection\\.conda\\lib\\site-packages (from tensorflow==2.6.4) (0.38.4)\n","Collecting termcolor~=1.1.0\n","  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Collecting h5py~=3.1.0\n","  Downloading h5py-3.1.0-cp37-cp37m-win_amd64.whl (2.7 MB)\n","     ---------------------------------------- 2.7/2.7 MB 18.9 MB/s eta 0:00:00\n","Collecting gast==0.4.0\n","  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Collecting clang~=5.0\n","  Using cached clang-5.0.tar.gz (30 kB)\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Collecting keras<2.7,>=2.6.0\n","  Using cached keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n","Collecting flatbuffers~=1.12.0\n","  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n","Collecting tensorboard<2.7,>=2.6.0\n","  Using cached tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n","Collecting grpcio<2.0,>=1.37.0\n","  Downloading grpcio-1.57.0-cp37-cp37m-win_amd64.whl (4.3 MB)\n","     ---------------------------------------- 4.3/4.3 MB 67.9 MB/s eta 0:00:00\n","Collecting protobuf>=3.9.2\n","  Downloading protobuf-4.24.1-cp37-cp37m-win_amd64.whl (429 kB)\n","     ---------------------------------------- 430.0/430.0 kB ? eta 0:00:00\n","Collecting tensorflow-estimator<2.7,>=2.6.0\n","  Using cached tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n","Collecting keras-preprocessing~=1.1.2\n","  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","Collecting astunparse~=1.6.3\n","  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n","Collecting absl-py~=0.10\n","  Using cached absl_py-0.15.0-py3-none-any.whl (132 kB)\n","Collecting google-pasta~=0.2\n","  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n","Collecting wrapt~=1.12.1\n","  Using cached wrapt-1.12.1.tar.gz (27 kB)\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Collecting typing-extensions<3.11,>=3.7\n","  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n","Collecting cached-property\n","  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n","Collecting markdown>=2.6.8\n","  Using cached Markdown-3.4.4-py3-none-any.whl (94 kB)\n","Collecting requests<3,>=2.21.0\n","  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0\n","  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n","Collecting google-auth<2,>=1.6.3\n","  Using cached google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n","Collecting tensorboard-plugin-wit>=1.6.0\n","  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n","Collecting werkzeug>=0.11.15\n","  Using cached Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n","Collecting google-auth-oauthlib<0.5,>=0.4.1\n","  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\louis\\documents\\github\\varroa-detection\\.conda\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow==2.6.4) (65.6.3)\n","Collecting pyasn1-modules>=0.2.1\n","  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n","Collecting cachetools<5.0,>=2.0.0\n","  Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\n","Collecting rsa<5,>=3.1.4\n","  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n","Collecting requests-oauthlib>=0.7.0\n","  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n","Collecting importlib-metadata>=4.4\n","  Downloading importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n","Collecting urllib3<3,>=1.21.1\n","  Downloading urllib3-2.0.4-py3-none-any.whl (123 kB)\n","     ---------------------------------------- 123.9/123.9 kB ? eta 0:00:00\n","Collecting charset-normalizer<4,>=2\n","  Downloading charset_normalizer-3.2.0-cp37-cp37m-win_amd64.whl (94 kB)\n","     ---------------------------------------- 94.7/94.7 kB ? eta 0:00:00\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\louis\\documents\\github\\varroa-detection\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow==2.6.4) (2022.12.7)\n","Collecting idna<4,>=2.5\n","  Using cached idna-3.4-py3-none-any.whl (61 kB)\n","Collecting MarkupSafe>=2.1.1\n","  Downloading MarkupSafe-2.1.3-cp37-cp37m-win_amd64.whl (17 kB)\n","Collecting zipp>=0.5\n","  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n","Collecting pyasn1<0.6.0,>=0.4.6\n","  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n","Collecting oauthlib>=3.0.0\n","  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n","Building wheels for collected packages: clang, termcolor, wrapt\n","  Building wheel for clang (setup.py): started\n","  Building wheel for clang (setup.py): finished with status 'done'\n","  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30701 sha256=667b3e040fb2e7d91e906d21e3eb7e84c72c32ec4c79a7608ff57acb4a48bcaa\n","  Stored in directory: c:\\users\\louis\\appdata\\local\\pip\\cache\\wheels\\51\\40\\ff\\2ba7d5d0dee868c4dddb5f9e7389c7ba8afd841a75ce58a576\n","  Building wheel for termcolor (setup.py): started\n","  Building wheel for termcolor (setup.py): finished with status 'done'\n","  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4855 sha256=5f52bef1e86ad350c508a182f54b19f5d008b3b97ff528566f7c546711a518e0\n","  Stored in directory: c:\\users\\louis\\appdata\\local\\pip\\cache\\wheels\\19\\b5\\5e\\dde0eb16713e5c2e7d5fc48df6c6d70cc85a7d665a7cdc399e\n","  Building wheel for wrapt (setup.py): started\n","  Building wheel for wrapt (setup.py): finished with status 'done'\n","  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-win_amd64.whl size=32705 sha256=1ed958858d7c1c352924aa39b3d8449a2023052cac75c9d430470ba113ad3313\n","  Stored in directory: c:\\users\\louis\\appdata\\local\\pip\\cache\\wheels\\70\\32\\b7\\c7efd67541df013b25b28029490a3d406b617e429923a26c72\n","Successfully built clang termcolor wrapt\n","Installing collected packages: wrapt, typing-extensions, termcolor, tensorflow-estimator, tensorboard-plugin-wit, keras, flatbuffers, clang, cached-property, zipp, urllib3, tensorboard-data-server, six, pyasn1, protobuf, oauthlib, numpy, MarkupSafe, idna, grpcio, gast, charset-normalizer, cachetools, werkzeug, rsa, requests, pyasn1-modules, opt-einsum, keras-preprocessing, importlib-metadata, h5py, google-pasta, astunparse, absl-py, requests-oauthlib, markdown, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n","  Attempting uninstall: six\n","    Found existing installation: six 1.16.0\n","    Uninstalling six-1.16.0:\n","      Successfully uninstalled six-1.16.0\n","Successfully installed MarkupSafe-2.1.3 absl-py-0.15.0 astunparse-1.6.3 cached-property-1.5.2 cachetools-4.2.4 charset-normalizer-3.2.0 clang-5.0 flatbuffers-1.12 gast-0.4.0 google-auth-1.35.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.57.0 h5py-3.1.0 idna-3.4 importlib-metadata-6.7.0 keras-2.6.0 keras-preprocessing-1.1.2 markdown-3.4.4 numpy-1.19.5 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.24.1 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-2.31.0 requests-oauthlib-1.3.1 rsa-4.9 six-1.15.0 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.6.4 tensorflow-estimator-2.6.0 termcolor-1.1.0 typing-extensions-3.10.0.2 urllib3-2.0.4 werkzeug-2.2.3 wrapt-1.12.1 zipp-3.15.0\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: keras==2.6.0 in c:\\users\\louis\\documents\\github\\varroa-detection\\.conda\\lib\\site-packages (2.6.0)\n","Note: you may need to restart the kernel to use updated packages.\n","Collecting matplotlib==3.5.2Note: you may need to restart the kernel to use updated packages.\n","\n","  Downloading matplotlib-3.5.2-cp37-cp37m-win_amd64.whl (7.2 MB)\n","     ---------------------------------------- 7.2/7.2 MB 13.9 MB/s eta 0:00:00\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\louis\\documents\\github\\varroa-detection\\.conda\\lib\\site-packages (from matplotlib==3.5.2) (22.0)\n","Collecting pillow>=6.2.0\n","  Downloading Pillow-9.5.0-cp37-cp37m-win_amd64.whl (2.5 MB)\n","     ---------------------------------------- 2.5/2.5 MB 53.8 MB/s eta 0:00:00\n","Collecting fonttools>=4.22.0\n","  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n","     ------------------------------------- 965.4/965.4 kB 59.7 MB/s eta 0:00:00\n","Collecting cycler>=0.10\n","  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n","Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\louis\\documents\\github\\varroa-detection\\.conda\\lib\\site-packages (from matplotlib==3.5.2) (2.8.2)\n","Collecting kiwisolver>=1.0.1\n","  Downloading kiwisolver-1.4.4-cp37-cp37m-win_amd64.whl (54 kB)\n","     ---------------------------------------- 54.9/54.9 kB 3.0 MB/s eta 0:00:00\n","Requirement already satisfied: numpy>=1.17 in c:\\users\\louis\\documents\\github\\varroa-detection\\.conda\\lib\\site-packages (from matplotlib==3.5.2) (1.19.5)\n","Collecting pyparsing>=2.2.1\n","  Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n","     -------------------------------------- 103.1/103.1 kB 6.2 MB/s eta 0:00:00\n","Requirement already satisfied: typing-extensions in c:\\users\\louis\\documents\\github\\varroa-detection\\.conda\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib==3.5.2) (3.10.0.2)\n","Requirement already satisfied: six>=1.5 in c:\\users\\louis\\documents\\github\\varroa-detection\\.conda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib==3.5.2) (1.15.0)\n","Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, matplotlib\n","Successfully installed cycler-0.11.0 fonttools-4.38.0 kiwisolver-1.4.4 matplotlib-3.5.2 pillow-9.5.0 pyparsing-3.1.1\n","Collecting numpy==1.21.6\n","  Downloading numpy-1.21.6-cp37-cp37m-win_amd64.whl (14.0 MB)\n","     --------------------------------------- 14.0/14.0 MB 36.4 MB/s eta 0:00:00\n","Installing collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","Successfully installed numpy-1.21.6\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.6.4 requires numpy~=1.19.2, but you have numpy 1.21.6 which is incompatible.\n"]},{"name":"stdout","output_type":"stream","text":["Collecting pillow==9.1.1\n","  Downloading Pillow-9.1.1-cp37-cp37m-win_amd64.whl (3.3 MB)\n","     ---------------------------------------- 3.3/3.3 MB 14.9 MB/s eta 0:00:00\n","Installing collected packages: pillow\n","  Attempting uninstall: pillow\n","    Found existing installation: Pillow 9.5.0\n","    Uninstalling Pillow-9.5.0:\n","      Successfully uninstalled Pillow-9.5.0\n","Successfully installed pillow-9.1.1\n","Note: you may need to restart the kernel to use updated packages.\n","Collecting scikit-learn==1.0.2\n","  Downloading scikit_learn-1.0.2-cp37-cp37m-win_amd64.whl (7.1 MB)\n","     ---------------------------------------- 7.1/7.1 MB 41.5 MB/s eta 0:00:00\n","Collecting joblib>=0.11\n","  Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n","Collecting threadpoolctl>=2.0.0\n","  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n","Collecting scipy>=1.1.0\n","  Downloading scipy-1.7.3-cp37-cp37m-win_amd64.whl (34.1 MB)\n","     --------------------------------------- 34.1/34.1 MB 34.4 MB/s eta 0:00:00\n","Requirement already satisfied: numpy>=1.14.6 in c:\\users\\louis\\documents\\github\\varroa-detection\\.conda\\lib\\site-packages (from scikit-learn==1.0.2) (1.21.6)\n","Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n","Successfully installed joblib-1.3.2 scikit-learn-1.0.2 scipy-1.7.3 threadpoolctl-3.1.0\n","Note: you may need to restart the kernel to use updated packages.\n","Collecting opencv-python==4.5.4.60\n","  Downloading opencv_python-4.5.4.60-cp37-cp37m-win_amd64.whl (35.1 MB)\n","     ---------------------------------------- 35.1/35.1 MB 6.2 MB/s eta 0:00:00\n","Requirement already satisfied: numpy>=1.14.5 in c:\\users\\louis\\documents\\github\\varroa-detection\\.conda\\lib\\site-packages (from opencv-python==4.5.4.60) (1.21.6)\n","Installing collected packages: opencv-python\n","Successfully installed opencv-python-4.5.4.60\n","Note: you may need to restart the kernel to use updated packages.\n","Collecting pandas==1.3.5\n","  Downloading pandas-1.3.5-cp37-cp37m-win_amd64.whl (10.0 MB)\n","     --------------------------------------- 10.0/10.0 MB 30.4 MB/s eta 0:00:00\n","Collecting pytz>=2017.3\n","  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n","Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\louis\\documents\\github\\varroa-detection\\.conda\\lib\\site-packages (from pandas==1.3.5) (2.8.2)\n","Requirement already satisfied: numpy>=1.17.3 in c:\\users\\louis\\documents\\github\\varroa-detection\\.conda\\lib\\site-packages (from pandas==1.3.5) (1.21.6)\n","Requirement already satisfied: six>=1.5 in c:\\users\\louis\\documents\\github\\varroa-detection\\.conda\\lib\\site-packages (from python-dateutil>=2.7.3->pandas==1.3.5) (1.15.0)\n","Installing collected packages: pytz, pandas\n","Successfully installed pandas-1.3.5 pytz-2023.3\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"ename":"TypeError","evalue":"Descriptors cannot not be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14748\\3209155986.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mglob\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\louis\\Documents\\GitHub\\varroa-detection\\.conda\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\louis\\Documents\\GitHub\\varroa-detection\\.conda\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\louis\\Documents\\GitHub\\varroa-detection\\.conda\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunction_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrewriter_config_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\louis\\Documents\\GitHub\\varroa-detection\\.conda\\lib\\site-packages\\tensorflow\\core\\framework\\function_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mattr_value_pb2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_attr__value__pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnode_def_pb2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_node__def__pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mop_def_pb2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_op__def__pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\louis\\Documents\\GitHub\\varroa-detection\\.conda\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_pb2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_tensor__pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_shape_pb2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_types__pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\louis\\Documents\\GitHub\\varroa-detection\\.conda\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mresource_handle_pb2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_resource__handle__pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_shape_pb2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_types__pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\louis\\Documents\\GitHub\\varroa-detection\\.conda\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_shape_pb2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_types__pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\louis\\Documents\\GitHub\\varroa-detection\\.conda\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m       \u001b[0mmessage_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menum_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontaining_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m       \u001b[0mis_extension\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension_scope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m       serialized_options=None, file=DESCRIPTOR),\n\u001b[0m\u001b[0;32m     43\u001b[0m     _descriptor.FieldDescriptor(\n\u001b[0;32m     44\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tensorflow.TensorShapeProto.Dim.name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\louis\\Documents\\GitHub\\varroa-detection\\.conda\\lib\\site-packages\\google\\protobuf\\descriptor.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, name, full_name, index, number, type, cpp_type, label, default_value, message_type, enum_type, containing_type, is_extension, extension_scope, options, serialized_options, has_default_value, containing_oneof, json_name, file, create_key)\u001b[0m\n\u001b[0;32m    559\u001b[0m                 \u001b[0mhas_default_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontaining_oneof\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m                 file=None, create_key=None):  # pylint: disable=redefined-builtin\n\u001b[1;32m--> 561\u001b[1;33m       \u001b[0m_message\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMessage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_CheckCalledFromGeneratedFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mis_extension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_pool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFindExtensionByName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mTypeError\u001b[0m: Descriptors cannot not be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates"]}],"source":["# python 3.7.12\n","# %pip install tensorflow==2.6.4\n","# %pip install keras==2.6.0\n","# %pip install matplotlib==3.5.2\n","# %pip install numpy==1.21.6\n","# %pip install pillow==9.1.1\n","# %pip install scikit-learn==1.0.2\n","# %pip install opencv-python==4.5.4.60\n","# %pip install pandas==1.3.5\n","\n","\n","\n","import six\n","import tensorflow as tf\n","from keras.preprocessing.image import ImageDataGenerator\n","from glob import glob\n","import math\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import MobileNetV2\n","from PIL import Image\n","import numpy as np\n","import os\n","from PIL import ImageFile\n","ImageFile.LOAD_TRUNCATED_IMAGES = True #In case there are broken png, ignore them\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T13:51:54.431643Z","iopub.status.busy":"2023-03-03T13:51:54.428279Z","iopub.status.idle":"2023-03-03T13:52:06.336193Z","shell.execute_reply":"2023-03-03T13:52:06.335081Z","shell.execute_reply.started":"2023-03-03T13:51:54.431597Z"},"trusted":true},"outputs":[],"source":["validation_split=0.2\n","image_data_generator = ImageDataGenerator(\n","                              rescale=1./255,\n","                              validation_split=validation_split)\n","\n","# Images for training\n","train_generator = image_data_generator.flow_from_directory(\n","                        \"./input/varroa-and-bees/bees_pictures/train\",\n","                        batch_size= 128,\n","                        class_mode= 'categorical',\n","                        target_size=(160, 280), \n","                        color_mode= 'rgb',\n","                        subset= 'training')\n","\n","# Images for validation\n","validation_generator = image_data_generator.flow_from_directory(\n","                             \"./input/varroa-and-bees/bees_pictures/train\",\n","                             batch_size= 128,\n","                             class_mode= 'categorical',\n","                             target_size=(160, 280), \n","                             color_mode= 'rgb',\n","                             subset= 'validation')\n","#target_size= (160, 280), "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T13:52:06.337937Z","iopub.status.busy":"2023-03-03T13:52:06.337523Z","iopub.status.idle":"2023-03-03T13:52:10.811745Z","shell.execute_reply":"2023-03-03T13:52:10.810709Z","shell.execute_reply.started":"2023-03-03T13:52:06.337871Z"},"trusted":true},"outputs":[],"source":["image_data_generator = ImageDataGenerator(rescale=1./255)\n","evaluation_generator = image_data_generator.flow_from_directory(\n","                                        \"../input/varroa-and-bees/bees_pictures/test\", \n","                                        batch_size=128,\n","                                        class_mode='categorical',\n","                                        target_size=(160, 280), \n","                                        color_mode='rgb')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T13:52:10.815645Z","iopub.status.busy":"2023-03-03T13:52:10.813778Z","iopub.status.idle":"2023-03-03T13:52:10.820958Z","shell.execute_reply":"2023-03-03T13:52:10.819811Z","shell.execute_reply.started":"2023-03-03T13:52:10.815605Z"},"trusted":true},"outputs":[],"source":["tf.config.threading.set_inter_op_parallelism_threads(1)\n","# learning_rate_decay = tf.keras.callbacks.LearningRateScheduler(step_decay, verbose=1)\n","image_width = 280\n","image_height = 160\n","batch_size = 128\n","\n","validation_split = 0.1\n","initial_learning_rate = 0.045\n","evaluation_steps = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-02T16:54:13.645664Z","iopub.status.busy":"2023-03-02T16:54:13.645352Z","iopub.status.idle":"2023-03-02T16:54:59.075544Z","shell.execute_reply":"2023-03-02T16:54:59.074538Z","shell.execute_reply.started":"2023-03-02T16:54:13.645636Z"},"trusted":true},"outputs":[],"source":["img_input = tf.keras.Input(shape=(image_height, image_width, 3))\n","\n","# Add convolutional layers\n","x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(img_input)\n","x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n","x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n","x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n","x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu')(x)\n","x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n","x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu')(x)\n","x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n","\n","# Add dense layers\n","x = tf.keras.layers.Flatten()(x)\n","x = tf.keras.layers.Dense(512, activation='relu')(x)\n","predictions = tf.keras.layers.Dense(2, activation='softmax')(x)\n","\n","# Create final model\n","model = tf.keras.models.Model(inputs=img_input, outputs=predictions)\n","\n","# Compile the model\n","model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001, clipvalue=2.0),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=5, restore_best_weights=True)\n","def step_decay(epoch, lr):\n","    drop = 0.04\n","    epochs_drop = 2.0\n","    lrate = lr * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n","    return lrate\n","\n","\n","all_files = glob('../input/varroa-and-bees/bees_pictures/train/*/*.png')\n","\n","num_validation = len(all_files) * validation_split\n","num_train = len(all_files) - num_validation\n","\n","validation_steps = int(num_validation / batch_size)\n","steps_per_epoch = int(num_train / batch_size)\n","num_test = len(all_files)\n","\n","history = model.fit(train_generator,\n","          validation_data=validation_generator,\n","          epochs=1,\n","          steps_per_epoch=30,\n","          validation_steps=validation_steps)#,\n","#           callbacks=[early_stopping, learning_rate_decay])\n","model.save(\"./models/model.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T13:52:17.588018Z","iopub.status.busy":"2023-03-03T13:52:17.587437Z","iopub.status.idle":"2023-03-03T13:52:24.149590Z","shell.execute_reply":"2023-03-03T13:52:24.148473Z","shell.execute_reply.started":"2023-03-03T13:52:17.587970Z"},"trusted":true},"outputs":[],"source":["models = [load_model(\"./models/model.h5\"), load_model(\"./models/model (1).h5\"), load_model(\"./models/model (2).h5\")]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T13:52:24.156867Z","iopub.status.busy":"2023-03-03T13:52:24.155095Z","iopub.status.idle":"2023-03-03T13:53:47.803245Z","shell.execute_reply":"2023-03-03T13:53:47.802099Z","shell.execute_reply.started":"2023-03-03T13:52:24.156825Z"},"trusted":true},"outputs":[],"source":["numb = 0\n","predictions = []\n","for model in models:\n","    numb+=1\n","    print(\"/n/nMODEL \"+ str(numb) +\" :\")\n","    predictions.append(model.predict(evaluation_generator))\n","    print(predictions)\n","    _, test_accuracy = model.evaluate(evaluation_generator, steps=evaluation_steps)\n","    print('Test accuracy: ' + str(round(test_accuracy * 100., 1)) + ' %')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-03T13:53:47.805329Z","iopub.status.busy":"2023-03-03T13:53:47.805014Z","iopub.status.idle":"2023-03-03T13:53:48.122720Z","shell.execute_reply":"2023-03-03T13:53:48.121452Z","shell.execute_reply.started":"2023-03-03T13:53:47.805302Z"},"trusted":true},"outputs":[],"source":["numb = 0\n","labels = [\"Healthy\", \"Infected\", \"None\"]\n","xyz = os.listdir('/kaggle/input/varroa-and-bees/bees_pictures/test/healthy')\n","print(\"there is \" + str(len(xyz)) + \" healthy bees\")\n","xyz = os.listdir('/kaggle/input/varroa-and-bees/bees_pictures/test/infected')\n","print(\"there is \" + str(len(xyz)) + \" infected bees\")\n","for prediction in predictions:\n","    numblab = [0,0,0,0,0]\n","    numb+=1\n","    print(\"/n/nMODEL \"+ str(numb) +\" :\")\n","    for p in prediction:\n","        highest_probability_index = np.argmax(p)\n","        truncated_probablity = np.float64(np.round(p,8))\n","        if np.max(p) < .6:\n","            highest_probability_index = len(labels)-1\n","        numblab[highest_probability_index] += 1\n","    numb2 = 0\n","    for label in labels:\n","        print(label + \" has \" + str(numblab[numb2]) + \" predictions\")\n","        numb2 += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-02T16:56:24.884359Z","iopub.status.busy":"2023-03-02T16:56:24.882207Z","iopub.status.idle":"2023-03-02T16:56:24.941808Z","shell.execute_reply":"2023-03-02T16:56:24.940952Z","shell.execute_reply.started":"2023-03-02T16:56:24.884322Z"},"trusted":true},"outputs":[],"source":["Image.open('./input/bees_pictures/train/infected/2017-08-28_09-30-00-1_500_dirty_glass.mp4-bee_id_6698-165-1.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-02T16:56:24.942973Z","iopub.status.busy":"2023-03-02T16:56:24.942682Z","iopub.status.idle":"2023-03-02T16:56:25.314407Z","shell.execute_reply":"2023-03-02T16:56:25.313024Z","shell.execute_reply.started":"2023-03-02T16:56:24.942945Z"},"trusted":true},"outputs":[],"source":["model.predict(np.array(Image.open('./input/bees_pictures/train/infected/2017-08-28_09-30-00-1_500_dirty_glass.mp4-bee_id_6698-165-1.png')))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"}},"nbformat":4,"nbformat_minor":4}
